{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с данными в pytorch\n",
    "\n",
    "https://pytorch.org/docs/stable/data.html\n",
    "Обычно работа с данными декомпозирована на два класса:\n",
    "    \n",
    "### `torch.utils.data.Dataset`\n",
    "\n",
    "Класс для работы с семплами. Сюда часто добавляют логику скачивания датасета, препроцессинг и аугментации.\n",
    "\n",
    "Для работы со своими данными нужно отнаследоваться от этого класса и реализовать два метода: `__len__` и `__getitem__`.\n",
    "Сначала мы воспользуемся готовым датасетом из [`torchvision.datasets`](https://pytorch.org/docs/stable/torchvision/datasets.html)\n",
    "\n",
    "### `torch.utils.data.Dataloader`\n",
    "\n",
    "Загрузчик данных, загружает семплы из Dataset, занимается семплирование, батчеванием, перемешиванием и т.д.\n",
    "Умеет в multiprocessing, это необходимо при работе со сколько-нибудь большими датасетами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# папку для загрузки можно поменять\n",
    "download_path = '/tmp'\n",
    "mnist_train = datasets.MNIST(download_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_val = datasets.MNIST(download_path, train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 0. (0.1 балла)**\n",
    "1. В каком виде возвращает семплы итератор по `mnist_train`?\n",
    "2. Отобразите несколько примеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# напишите ответ текстом или кодом здесь\n",
    "<your code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обязательно прсмотрите на то, в каком виде возвращаются семплы\n",
    "plt.figure(figsize=[6, 6])\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    # get img and label from mnist_train    \n",
    "    img, label = <your code here>\n",
    "\n",
    "    plt.title(\"Label: {}\".format(label))\n",
    "    plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(log, name=None):\n",
    "    if name is None:\n",
    "        name='loss'\n",
    "    train_points, val_points = [], []\n",
    "    train_key = 'train_{}'.format(name)\n",
    "    val_key = 'val_{}'.format(name)\n",
    "\n",
    "    for entry in log:\n",
    "        if train_key in entry:\n",
    "            train_points.append((entry['train_step'], entry[train_key]))\n",
    "        if val_key in entry:\n",
    "            val_points.append((entry['train_step'], entry[val_key]))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(name)\n",
    "    x, y = list(zip(*train_points))\n",
    "    plt.plot(x, y, label='train', zorder=1)\n",
    "    x, y = list(zip(*val_points))\n",
    "    plt.scatter(x, y, label='val', zorder=2, marker='+', s=180, c='orange')\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def train_model(model, optimizer, train_dataset, val_dataset, batch_size=32, epochs=10):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    log = []\n",
    "    train_step = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in tqdm(train_loader):\n",
    "            <your code here>\n",
    "            acc = ...\n",
    "            loss = ...\n",
    "            \n",
    "            log.append(dict(\n",
    "                train_loss=loss,\n",
    "                train_acc=acc,\n",
    "                train_step=train_step,\n",
    "            ))\n",
    "            train_step += 1\n",
    "\n",
    "        tmp = defaultdict(list)\n",
    "        model.eval()\n",
    "        for x, y in tqdm(val_loader):\n",
    "            with torch.no_grad():\n",
    "                <your code here>\n",
    "                acc = ...\n",
    "                loss = ...\n",
    "                \n",
    "                tmp['acc'].append(acc)\n",
    "                tmp['loss'].append(loss\n",
    "                \n",
    "        log.append(dict(\n",
    "            val_loss = np.mean(tmp['loss']),  # скаляры\n",
    "            val_acc = np.concatenate(tmp['acc']).mean(),  # массивы, возможно разной длины\n",
    "            train_step=train_step,\n",
    "        ))\n",
    "        \n",
    "        clear_output()\n",
    "        plot_history(log, name='loss')\n",
    "        plot_history(log, name='acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сверточные сети\n",
    "\n",
    "Мы рассмотрим сверточные сети на примере MNIST, заодно поучимся пользоваться стандартными pytorch-классами для работы с данными.\n",
    "\n",
    "В случае картинок, обычно работают с входными тензорами размера `[batch_size, channels, height, widht]` (такой порядок осей называется channels-first или NCHW).\n",
    "\n",
    "Сверточные сети обычно собираются из последовательности слоев:\n",
    "\n",
    "### Convolution\n",
    "https://pytorch.org/docs/stable/nn.html#convolution-layers\n",
    "\n",
    "По тензору бежит скользящее окно и в нем вычисляется свертка с ядром.\n",
    "Обычно говорят о пространственных размерах сверток, например 1x1 или 3x3  свертки, подразумевая, что ядра имеют размер `[1,1,ch]` или `[3,3,ch]`.\n",
    "\n",
    "Сейчас часто используются чуть более сложные варианты сверток: \n",
    "- dilated (atrous, дырявые), \n",
    "- depth-wise\n",
    "- pointwise\n",
    "- separable\n",
    "- group\n",
    "\n",
    "\n",
    "### Pooling\n",
    "https://pytorch.org/docs/stable/nn.html#pooling-layers\n",
    "\n",
    "Действуют аналогично свертках, но не имеют весов, а в бегущем окне вычисляется какая-нибудь функция, например max или mean.\n",
    "\n",
    "\n",
    "### Global pooling (Adaptive Pooling)\n",
    "https://pytorch.org/docs/stable/nn.html#adaptivemaxpool1d\n",
    "\n",
    "Глобальные пулинги (в pytorch адаптивные) убирают пространственные размерности, превращая `[bs, ch, h, w]` в `[bs, ch, 1, 1]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 1 (0.2 балла)\n",
    "\n",
    "1. Реализуйте сверточную сеть, 2xConv+ReLU+MPooling + Dense.\n",
    "**Hint: Воспользуйтесь оберткой `nn.Sequential`**\n",
    "\n",
    "2. Натренируйте модель с помощью функции train_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        <your code here>\n",
    "        \n",
    "    def forward(self, x):\n",
    "        <your code here>\n",
    "        return <something>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch предоставляет ряд методов для обхода весов в моделях\n",
    "# так можно посчитать количество обучаемых параметров, или построить изображение вычислительного графа\n",
    "def count_parameters(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    return sum([np.prod(p.size()) for p in model_parameters])\n",
    "\n",
    "model = ConvNet()\n",
    "print(\"Total number of trainable parameters:\", count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ошибка классификации после обучения должна быть ниже 1.5%\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "train_model(model, opt, mnist_train, mnist_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Затухающие и взрывающиеся градиенты\n",
    "\n",
    "Продолжаем экспериментировать с MNIST. \n",
    "В этом разделе нас будут интересовать особенности обучения глубоких сетей.\n",
    "\n",
    "1. Напишите свою функцию train_model, которая помимо графиков acc/loss будет подсчитывать нормы градиентов на каждом тренировочном шаге для кажого из обучаемых слоев.\n",
    "\n",
    "2. Напишите класс для построения сеток с произвольным количеством слоев и произвольными активациями\n",
    "\n",
    "3. Проведите ряд экспериментов для сверточной сети и для сетей с полносвязными слоями.\n",
    "\n",
    "\n",
    "\n",
    "**Hint: вам может пригодиться `model.named_parameters()` чтобы обойти слои модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grads(grad_log):\n",
    "    buffers = defaultdict(list)\n",
    "    \n",
    "    for entry in grad_log:\n",
    "        for k, v in entry.items():\n",
    "            buffers[k].append(v)\n",
    "    \n",
    "    names_to_plot = sorted(set(buffers.keys()).difference({'train_step'}))\n",
    "    steps = buffers['train_step']\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title('grads')\n",
    "    \n",
    "    for i, name in enumerate(names_to_plot):\n",
    "        plt.semilogy(\n",
    "            buffers[name], label=name, \n",
    "            color=plt.cm.coolwarm(i / len(names_to_plot)),\n",
    "        )    \n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, train_dataset, val_dataset, batch_size=32, epochs=10):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    grad_log, log = [], []\n",
    "    train_step = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in tqdm(train_loader):\n",
    "            <your code>\n",
    "            entry = {}\n",
    "            entry['train_step'] = train_step\n",
    "            grad_log.append(entry)\n",
    "            \n",
    "            log.append(dict(\n",
    "                train_loss=...,\n",
    "                train_acc=...,\n",
    "                train_step=train_step,\n",
    "            ))\n",
    "            train_step += 1\n",
    "\n",
    "        tmp = defaultdict(list)\n",
    "        model.eval()\n",
    "        for x, y in tqdm(val_loader):\n",
    "            with torch.no_grad():\n",
    "                <your code>\n",
    "                acc = ...\n",
    "                loss = ...\n",
    "                tmp['acc'].append(acc)\n",
    "                tmp['loss'].append(loss\n",
    "                \n",
    "        log.append(dict(\n",
    "            val_loss = np.mean(tmp['loss']),  # скаляры\n",
    "            val_acc = np.concatenate(tmp['acc']).mean(),  # массивы, возможно разной длины\n",
    "            train_step=train_step,\n",
    "        ))\n",
    "        \n",
    "        clear_output()\n",
    "        plot_history(log, name='loss')\n",
    "        plot_history(log, name='acc')\n",
    "        plot_grads(grad_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверим на сверточной сети\n",
    "model = ConvNet()\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "x = train_model(model, opt, mnist_train, mnist_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3 (0.2)** Реализуйте построение сети с произвольным числом (>1) полносвязных слоев с задаваемой функцией активации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, num_layers, hidden_size, activation):\n",
    "        super().__init__()\n",
    "        <your code here>\n",
    "        \n",
    "    def forward(self, x):\n",
    "        <your code here>\n",
    "        return <something>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4 (0.3 балла)**  Проведите ряд экспериментов с градиентами для 10 слоев и функций активаций {Sigmoid, ReLU}.\n",
    "\n",
    "Hidden size можно взять 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 слоев по 10, Sigmoid\n",
    "model = DenseNet(...)\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "x = train_model(model, opt, mnist_train, mnist_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 слоев по 10, ReLU\n",
    "model = DenseNet(...)\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "x = train_model(model, opt, mnist_train, mnist_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 5(0.2 балла)** Добавьте skip-connections и проверьте как протекают градиенты для 20 слоев и Sigmoid функции активации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseResNet(nn.Module):\n",
    "    def __init__(self, num_layers, hidden_size, activation):\n",
    "        super().__init__()\n",
    "        <your code here>\n",
    "        \n",
    "    def forward(self, x):\n",
    "        <your code here>\n",
    "        return <something>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 слоев по 10, Sigmoid\n",
    "model = DenseResNet(...)\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "x = train_model(model, opt, mnist_train, mnist_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
