{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом семинаре необходимо будет (1) реализовать простейшую metric learning архитектуру на основе сиамской нейросети с Contrastive Loss и использовать ее для поиска похожих изображений (2) реализовать fully convolutional сеть для задачи image super-resolution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Learning (0.7 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from  torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import Sampler, BatchSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.modules.loss import MSELoss\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам необходимо реализовать вычисление Contrastive Loss - одну из самых популярных функций потерь для metric learning. Contrastive Loss получает на вход пару векторов $x_i$ и $x_j$ (признаковые описания объектов $i$ и $j$, полученные нейросетью) и метку $y_{ij}$, причем $y_{ij} = 0$, если объекты \"похожи\" (принадлежат одному классу), и $y_{ij} = 1$, если объекты \"различны\" (принадлежат различным классам). Формально определим Contrastive Loss следующим образом:\n",
    "\n",
    "$$\n",
    "L(x_i, x_j, y_{ij}) = (1 - y_{ij})\\|x_i - x_j\\|^2 + y_{ij}max(0, m - \\|x_i - x_j\\|^2)\n",
    "$$\n",
    "\n",
    "где $m$ - гиперпараметр (его можно взять равным единице).\n",
    "\n",
    "Вместо того, чтобы формировать обучающее множество из всевозможных пар, можно поступить проще: будем пропускать батч из $N$ обучаюших изображений через сеть (тем самым получая соответствующие векторы $x$), а значение лосса вычислять как среднее значение функции $L$ на всех парах в этом батче. Тогда в обучении на каждом батче участвует $\\frac{N(N-1)}{2}$ пар, что существенно ускоряет сходимость на практике. Реализуйте предложенный вариант Contrastive Loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        <your code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задачах metric learning, как правило, необходимо, чтобы количества \"положительных\" и \"отрицательных\" пар в обучении отличалось несильно. Поэтому в случае большого количества классов случайное формирование батчей неэффективно - в таком случае количество \"положительных\" пар очень мало. Поэтому будем формировать обучающие батчи размера $N$ следующим образом: будем брать $\\frac{N}{2}$ элементов из некоторого класса (они между собой будут формировать \"положительные пары\"), а оставшиеся $\\frac{N}{2}$ элементов будем брать случайно. Таким образом мы гарантируем, что в каждом обучающем батче будет достаточно \"положительных\" пар.\n",
    "\n",
    "Реализуйте предложенную логику в рамках Pytorch, реализовав собственный BatchSampler. Ваш самплер должен формировать каждый батч размера $N$ следующим образом: $\\frac{N}{2}$ объектов извлекаются из некоторого случайного класса, оставшиеся $\\frac{N}{2}$ объектов извлекаются случайно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveSampler(BatchSampler):\n",
    "    def __init__(self, batch_size, num_classes, labels):\n",
    "        self.num_classes = num_classes\n",
    "        self.imgs_per_class = labels.size()[0] // num_classes\n",
    "        <your code>\n",
    "        \n",
    "    def __iter__(self):\n",
    "        num_yielded = 0\n",
    "        while num_yielded < (self.num_classes * self.imgs_per_class):\n",
    "            batch = []\n",
    "            <your code>\n",
    "            num_yielded += self.batch_size\n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании будем работать с небольшими изображениями одежды из датасета Fashion-MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "num_classes = 10\n",
    "batch_size = 256\n",
    "\n",
    "\n",
    "download_path = '/tmp'\n",
    "train_dataset = datasets.FashionMNIST(root=download_path, \n",
    "                                   train=True, \n",
    "                                   transform=transforms.ToTensor(),\n",
    "                                   download=True)\n",
    "\n",
    "test_dataset = dsets.FashionMNIST(root=download_path, \n",
    "                                  train=False, \n",
    "                                  transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_sampler=ContrastiveSampler(batch_size=batch_size, num_classes=num_classes, labels=train_dataset.train_labels), \n",
    "    shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, \n",
    "    batch_sampler=ContrastiveSampler(batch_size=batch_size, num_classes=num_classes, labels=test_dataset.test_labels), \n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте сеть несложной архитектуры, содержащую три сверточных слоя из 20 фильтров с макс-пулингом, а также два полносвязных слоя из 128 нейронов. Выход последнего слоя будет подаваться на вход Contrastive Loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size()[0], -1)\n",
    "\n",
    "class ContrastiveNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            <your code>\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.cnn1(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наши обычные функции для тренировки и отображения графиков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(log, name=None):\n",
    "    \"\"\"log is list of dictionaries like \n",
    "        [\n",
    "            {'train_step': 0, 'train_loss': 10.0, 'train_acc': 0.0}, \n",
    "            ...\n",
    "            {'train_step': 100, 'val_loss': 0.1, 'val_acc': 0.9},\n",
    "            ...\n",
    "        ]\n",
    "    \"\"\"\n",
    "    if name is None:\n",
    "        name='loss'\n",
    "    train_points, val_points = [], []\n",
    "    train_key = 'train_{}'.format(name)\n",
    "    val_key = 'val_{}'.format(name)\n",
    "\n",
    "    for entry in log:\n",
    "        if train_key in entry:\n",
    "            train_points.append((entry['train_step'], entry[train_key]))\n",
    "        if val_key in entry:\n",
    "            val_points.append((entry['train_step'], entry[val_key]))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(name)\n",
    "    x, y = list(zip(*train_points))\n",
    "    plt.plot(x, y, label='train', zorder=1)\n",
    "    x, y = list(zip(*val_points))\n",
    "    plt.scatter(x, y, label='val', zorder=2, marker='+', s=180, c='orange')\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrastive_loss = ContrastiveLoss()\n",
    "\n",
    "def train_model(model, optimizer, train_loader, val_loader, epochs=3):\n",
    "    log = []\n",
    "    train_step = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = contrastive_loss(output, y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            log.append(dict(\n",
    "                train_loss=loss.item(),\n",
    "                train_step=train_step,\n",
    "            ))\n",
    "            train_step += 1\n",
    "\n",
    "        # валидационные метрики надо усредних за все валидационные батчи\n",
    "        # hint: для аккумулирования величин удобно взять defaultdict\n",
    "        tmp = defaultdict(list)\n",
    "        model.eval()\n",
    "        for x, y in tqdm(val_loader):\n",
    "            with torch.no_grad():\n",
    "                output = model(x)\n",
    "                loss = contrastive_loss(output, y)\n",
    "                tmp['loss'].append(loss.item())\n",
    "                \n",
    "                \n",
    "        log.append(dict(\n",
    "            val_loss = np.mean(tmp['loss']),  # скаляры\n",
    "            train_step=train_step,\n",
    "        ))\n",
    "        \n",
    "        clear_output()\n",
    "        plot_history(log, name='loss') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите сеть с параметрами, указанными ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ContrastiveNetwork()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "train_model(model, opt, train_loader, test_loader, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Извлеките векторные описания тестовых изображений (a.k.a эмбеддинги). У вас должно получиться 10000 128-мерных векторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImages = test_dataset.test_data\n",
    "embeddings = model(Variable(test_dataset.test_data.view(-1,1,28,28)).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код ниже демонстрирует поисковую выдачу для трех изображений-запросов. Выдача формируется на основе близости эмбеддингов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryCount = 3\n",
    "queries = embeddings[:queryCount,:].data.numpy()\n",
    "database = embeddings[queryCount:,:].data.numpy()\n",
    "plt.figure(figsize=[15, 4.5])\n",
    "for i in range(queryCount):\n",
    "    results = np.argsort(np.sum((database-queries[i,:])**2, axis=1))[:10]\n",
    "    plt.subplot(queryCount, 11, i * 11 + 1)\n",
    "    plt.title(\"Query: %i\" % i)\n",
    "    plt.imshow(test_dataset.test_data[i].numpy().reshape([28, 28]), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    for k in range(10):\n",
    "        plt.subplot(queryCount, 11, i * 11 + k + 2)\n",
    "        plt.imshow(test_dataset.test_data[results[k]+queryCount].numpy().reshape([28, 28]), cmap='gray')\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super-resolution (0.3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части вам предстоит реализовать простейшую архитектуру для решения задачи image super-resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "num_classes = 10\n",
    "batch_size = 256\n",
    "\n",
    "download_path = '/tmp'\n",
    "train_dataset = datasets.MNIST(root=download_path, \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root=download_path, \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=batch_size,         \n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем увеличивать изображения размера (14,14) в два раза по каждому измерению. Как правило, перед подачей на вход нейросети изображение низкого разрешения увеличивают до нужного размера билинейной интерполяцией, а нейросеть улучшает результат интерполяции, не меняя пространственные размеры изображения.\n",
    "\n",
    "Реализуйте нейросеть из трех сверточных слоев (10 фильтров на каждом слое), которая будет получать на вход черно-белое изображение и выдавать на выход изображение такого же размера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperResolutionNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            <your code>\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.cnn1(x)\n",
    "        return output + x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам потребуется несколько переписать тренировку:\n",
    "- метки классов не нужны\n",
    "- таргет будем получать с помощью ресайзов из входных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_res_and_high_res(images_batch):\n",
    "    result = images_batch.clone()\n",
    "    low_res_transform = transforms.Resize((14,14))\n",
    "    high_res_transform = transforms.Resize((28,28))\n",
    "    toTensorTransform = transforms.ToTensor()\n",
    "    toImageTransform = transforms.ToPILImage()\n",
    "    for i in range(images_batch.size()[0]):\n",
    "        result[i] = toTensorTransform(high_res_transform(low_res_transform(toImageTransform(images_batch[i]))))\n",
    "    return result\n",
    "\n",
    "\n",
    "def train_super_res_model(model, optimizer, train_loader, val_loader, epochs=3):\n",
    "    log = []\n",
    "    train_step = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x, _ in tqdm(train_loader):\n",
    "            target = low_res_and_high_res(x)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)        \n",
    "            loss = F.mse_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            log.append(dict(\n",
    "                train_loss=loss.item(),\n",
    "                train_step=train_step,\n",
    "            ))\n",
    "            train_step += 1\n",
    "\n",
    "        # валидационные метрики надо усредних за все валидационные батчи\n",
    "        # hint: для аккумулирования величин удобно взять defaultdict\n",
    "        tmp = defaultdict(list)\n",
    "        model.eval()\n",
    "        for x, y in tqdm(val_loader):\n",
    "            with torch.no_grad():\n",
    "                target = low_res_and_high_res(x)\n",
    "                output = model(x)\n",
    "                loss = F.mse_loss(output, target)\n",
    "                tmp['loss'].append(loss.item())\n",
    "                \n",
    "        log.append(dict(\n",
    "            val_loss = np.mean(tmp['loss']),  # скаляры\n",
    "            train_step=train_step,\n",
    "        ))\n",
    "        \n",
    "        clear_output()\n",
    "        plot_history(log, name='loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимизируйте сеть с параметрами, указанными ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SuperResolutionNetwork()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.05)\n",
    "train_super_res_model(model, opt, train_loader, test_loader, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_dataset.test_data.float() / 255\n",
    "test_images_blurred = low_res_and_high_res(test_images[:100].view(-1,1,28,28))\n",
    "result_cnn = model(Variable(test_images_blurred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код ниже визуализирует исходные изображения (28,28) и реконструкции, полученные с помощью нейросети.\n",
    "Не удивляйтесь, есть качество реконструкций покажется низким, скоро вы узнаете, что MSE-loss, который мы использовали при обучении, не является оптимальным для задачи super-resolution (гораздо лучше работают adversarial-сети, про которые вам расскажут через пару недель)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examplesCount = 6\n",
    "plt.figure(figsize=[10, 10])\n",
    "for i in range(examplesCount):\n",
    "    plt.subplot(examplesCount, 3, i * 3 + 1)\n",
    "    plt.title(\"Original: %i\" % i)\n",
    "    plt.imshow(test_dataset.test_data[i].numpy().reshape([28, 28]), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(examplesCount, 3, i * 3 + 2)\n",
    "    plt.title(\"Super-ressed: %i\" % i)\n",
    "    plt.imshow(np.clip(result_cnn[i].data.numpy().reshape([28, 28]), 0, 1), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(examplesCount, 3, i * 3 + 3)\n",
    "    plt.title(\"Upscaled initial %i\" % i)\n",
    "    plt.imshow(test_images_blurred[i].numpy().reshape([28, 28]), cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
