{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При работе с гибкими инструментами стоит придерживаться распространенных подходов.\n",
    "Это касается организации кода, работы с данными, написания моделей и т.д.\n",
    "\n",
    "**План этого семинара:**\n",
    "\n",
    "1. Работа с данными в pytorch. Dataset&Dataloader\n",
    "2. Написание сверточной сети\n",
    "3. Написание кода тренировки\n",
    "4. Исследование затухания градиентов на примере полносвязных сетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Работа с данными в pytorch\n",
    "\n",
    "https://pytorch.org/docs/stable/data.html\n",
    "Обычно работа с данными декомпозирована на два класса:\n",
    "    \n",
    "### `torch.utils.data.Dataset`\n",
    "\n",
    "Класс для работы с семплами. Сюда часто добавляют логику скачивания датасета, препроцессинг и аугментации.\n",
    "\n",
    "Для работы со своими данными нужно отнаследоваться от этого класса и реализовать два метода: `__len__` и `__getitem__`.\n",
    "Сначала мы воспользуемся готовым датасетом из [`torchvision.datasets`](https://pytorch.org/docs/stable/torchvision/datasets.html)\n",
    "\n",
    "### `torch.utils.data.Dataloader`\n",
    "\n",
    "Загрузчик данных, загружает семплы из Dataset, занимается семплирование, батчеванием, перемешиванием и т.д.\n",
    "Умеет в multiprocessing, это необходимо при работе со сколько-нибудь большими датасетами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# папку для загрузки можно поменять\n",
    "download_path = '/tmp'\n",
    "mnist_train = datasets.MNIST(download_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_val = datasets.MNIST(download_path, train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 0. (0.1 балла)**\n",
    "1. В каком виде возвращает семплы итератор по `mnist_train`?\n",
    "2. Отобразите несколько примеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# напишите ответ текстом или кодом здесь\n",
    "<your code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обязательно смотрите на то, в каком виде возвращаются семплы\n",
    "plt.figure(figsize=[6, 6])\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    img, label = <your code here>\n",
    "    \n",
    "    plt.title(\"Label: {}\".format(label))\n",
    "    plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сверточные сети\n",
    "\n",
    "Мы рассмотрим сверточные сети на примере MNIST, заодно поучимся пользоваться стандартными pytorch-классами для работы с данными.\n",
    "\n",
    "В случае картинок, обычно работают с входными тензорами размера `[batch_size, channels, height, widht]` (такой порядок осей называется channels-first или NCHW).\n",
    "\n",
    "Сверточные сети обычно собираются из последовательности слоев:\n",
    "\n",
    "### Convolution\n",
    "https://pytorch.org/docs/stable/nn.html#convolution-layers\n",
    "\n",
    "По тензору бежит скользящее окно и в нем вычисляется свертка с ядром.\n",
    "Обычно говорят о пространственных размерах сверток, например 1x1 или 3x3  свертки, подразумевая, что ядра имеют размер `[1,1,ch]` или `[3,3,ch]`.\n",
    "\n",
    "Сейчас часто используются чуть более сложные варианты сверток: \n",
    "- dilated (atrous, дырявые), \n",
    "- depth-wise\n",
    "- pointwise\n",
    "- separable\n",
    "- group\n",
    "\n",
    "\n",
    "### Pooling\n",
    "https://pytorch.org/docs/stable/nn.html#pooling-layers\n",
    "\n",
    "Действуют аналогично свертках, но не имеют весов, а в бегущем окне вычисляется какая-нибудь функция, например max или mean.\n",
    "\n",
    "\n",
    "### Global pooling (Adaptive Pooling)\n",
    "https://pytorch.org/docs/stable/nn.html#adaptivemaxpool1d\n",
    "\n",
    "Глобальные пулинги (в pytorch адаптивные) убирают пространственные размерности, превращая `[bs, ch, h, w]` в `[bs, ch, 1, 1]`.\n",
    "\n",
    "\n",
    "\n",
    "Удобно выделять в сверточных сетях две части: полносверточную (body, feature extractor, тушка) и классификатор (head, голова).\n",
    "\n",
    "Классификатор обычно состоит из полносвязных слоев (и где-то может обозначаться как MLP, MLP-head), и требует фиксированного размера тензоров (batch_size может варьироваться, но остальные размерности фиксированы).\n",
    "\n",
    "Полносверточная часть обычно может работать на входах произвольных размеров (не меньше минимального).\n",
    "\n",
    "\n",
    "Чтобы объединить эти две части используют какую-нибудь из операций: **Flatten** или **Global Pooling**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 1 (0.2 балла)\n",
    "\n",
    "Реализуйте сверточную сеть, *2x(Conv+ReLU+MaxPooling) + Flatten + Dense*.\n",
    "\n",
    "Ошибка классификации после обучения должна быть ниже 1.5%\n",
    "\n",
    "Количество каналов и размеры фильтров выбирайте по желанию, начните с небольших чисел ~8-16.\n",
    "\n",
    "**Hint: Для последовательности слоев без skip-connections удобно пользоваться оберткой `nn.Sequential`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        <your code here>\n",
    "        \n",
    "    def forward(self, x):\n",
    "        <your code here>\n",
    "        \n",
    "model = ConvNet()\n",
    "# В качестве быстрой проверки корректности попробуем прогнать через сеть тензор нужного размера\n",
    "# [bs, ch, h, w]\n",
    "x = torch.zeros([4, 1, 28, 28])\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стандартный цикл тренировки модели выглядит так:\n",
    "```python\n",
    "for epoch in epochs:\n",
    "   model.train()\n",
    "   for x, y in train_loader:\n",
    "        ...\n",
    "   model.eval()\n",
    "   for x, y in val_loader:\n",
    "        ...\n",
    "```\n",
    "\n",
    "В этом семинаре логгирование мы пишем самостоятельно, в дальнейшем вы можете использовать\n",
    "этот код, tensorboardx или visdom на свое усмотрение.\n",
    "\n",
    "Тренировочный цикл можно заменить на pytorch.ignite, но для учебных целей мы пока будем писать целиком так."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(log, name=None):\n",
    "    \"\"\"log is list of dictionaries like \n",
    "        [\n",
    "            {'train_step': 0, 'train_loss': 10.0, 'train_acc': 0.0}, \n",
    "            ...\n",
    "            {'train_step': 100, 'val_loss': 0.1, 'val_acc': 0.9},\n",
    "            ...\n",
    "        ]\n",
    "    \"\"\"\n",
    "    if name is None:\n",
    "        name='loss'\n",
    "    train_points, val_points = [], []\n",
    "    train_key = 'train_{}'.format(name)\n",
    "    val_key = 'val_{}'.format(name)\n",
    "\n",
    "    for entry in log:\n",
    "        if train_key in entry:\n",
    "            train_points.append((entry['train_step'], entry[train_key]))\n",
    "        if val_key in entry:\n",
    "            val_points.append((entry['train_step'], entry[val_key]))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(name)\n",
    "    x, y = list(zip(*train_points))\n",
    "    plt.plot(x, y, label='train', zorder=1)\n",
    "    x, y = list(zip(*val_points))\n",
    "    plt.scatter(x, y, label='val', zorder=2, marker='+', s=180, c='orange')\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допишите тренировочный цикл:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, train_dataset, val_dataset, batch_size=32, epochs=10):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    log = []\n",
    "    train_step = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in tqdm(train_loader):\n",
    "            <your code here>\n",
    "            \n",
    "            loss = ....\n",
    "            acc = ...\n",
    "            \n",
    "            log.append(dict(\n",
    "                train_loss=loss,\n",
    "                train_acc=acc,\n",
    "                train_step=train_step,\n",
    "            ))\n",
    "            train_step += 1\n",
    "\n",
    "        # валидационные метрики надо усредних за все валидационные батчи\n",
    "        # hint: для аккумулирования величин удобно взять defaultdict\n",
    "        tmp = defaultdict(list)\n",
    "        model.eval()\n",
    "        for x, y in tqdm(val_loader):\n",
    "            with torch.no_grad():\n",
    "                <your code here>\n",
    "                \n",
    "                acc = ...\n",
    "                loss = ...\n",
    "                \n",
    "                tmp['acc'].append(acc)\n",
    "                tmp['loss'].append(loss)\n",
    "                \n",
    "                \n",
    "        log.append(dict(\n",
    "            val_loss = np.mean(tmp['loss']),\n",
    "            val_acc = np.mean(tmp['acc']),\n",
    "            train_step=train_step,\n",
    "        ))\n",
    "        \n",
    "        clear_output()\n",
    "        plot_history(log, name='loss')\n",
    "        plot_history(log, name='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обратите внимание на способ обхода весов модели:\n",
    "def count_parameters(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    return sum([np.prod(p.size()) for p in model_parameters])\n",
    "\n",
    "model = ConvNet()\n",
    "print(\"Total number of trainable parameters:\", count_parameters(model))\n",
    "\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "train_model(model, opt, mnist_train, mnist_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Затухающие градиенты\n",
    "\n",
    "Продолжаем экспериментировать с MNIST. \n",
    "\n",
    "В этом разделе нас будут интересовать особенности обучения глубоких сетей.\n",
    "\n",
    "Эксперименты со сверточными сетями оказываются вычислительно дорогими, поэтому градиенты будем исследовать в полносвязных сетях.\n",
    "\n",
    "**Hint: вам может пригодиться `model.named_parameters()` чтобы обойти слои модели**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3 (0.2)** Реализуйте построение сети с произвольным числом (>1) полносвязных слоев с задаваемой функцией активации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, num_layers, hidden_size, activation):\n",
    "        super().__init__()\n",
    "        <your code here>\n",
    "        \n",
    "    def forward(self, x):\n",
    "        <your code here>\n",
    "\n",
    "\n",
    "model = DenseNet(10, 16, nn.Sigmoid)\n",
    "# В качестве быстрой проверки корректности попробуем прогнать через сеть тензор нужного размера\n",
    "# [bs, ch, h, w]\n",
    "x = torch.zeros([4, 1, 28, 28])\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте в тренировочный цикл подсчет и отображение градиентов по слоям. Для отображения шумных величин можно воспользоваться оконным сглаживанием.\n",
    "\n",
    "Нас интересуют нормы градиентов на каждом слое на каждом тренировочном шаге. \n",
    "\n",
    "Веса (weights) и смещения (biases) считать за разные величины.\n",
    "\n",
    "\n",
    "**Hint: вам может пригодиться `model.named_parameters()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grads(grad_log):\n",
    "    \"\"\"grad_log is list of dictionaries like \n",
    "        [\n",
    "            {'train_step': 0, 'grad_layer.0.weight': 0.1, 'grad_layer.0.bias': 0.01, ...}, \n",
    "            ...\n",
    "        ]\n",
    "    \"\"\"\n",
    "    buffers = defaultdict(list)\n",
    "    for entry in grad_log:\n",
    "        for k, v in entry.items():\n",
    "            buffers[k].append(v)\n",
    "    \n",
    "    names_to_plot = sorted(set(buffers.keys()).difference({'train_step'}))\n",
    "    steps = buffers['train_step']\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title('grads')\n",
    "    \n",
    "    for i, name in enumerate(names_to_plot):\n",
    "        plt.semilogy(\n",
    "            buffers[name], label=name, \n",
    "            color=plt.cm.coolwarm(i / len(names_to_plot)),\n",
    "        )    \n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, train_dataset, val_dataset, batch_size=32, epochs=10):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    grad_log = []\n",
    "    log = []\n",
    "    train_step = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in tqdm(train_loader):\n",
    "            <your code here>\n",
    "            \n",
    "            # кроме обычных тренировочных действий, обойдите все веса сети и посчитайте нормы градиентов для них\n",
    "            # добавьте в grad_log словарь вида {train_step: 0, grad_w0: 0.01, grad_w1: ...}.\n",
    "            entry = {...}\n",
    "            loss = ...\n",
    "            acc = ...\n",
    "            \n",
    "            entry['train_step'] = train_step\n",
    "            grad_log.append(entry)\n",
    "            log.append(dict(\n",
    "                train_loss=loss,\n",
    "                train_acc=acc,\n",
    "                train_step=train_step,\n",
    "            ))\n",
    "            train_step += 1\n",
    "\n",
    "        tmp = defaultdict(list)\n",
    "        model.eval()\n",
    "        for x, y in tqdm(val_loader):\n",
    "            with torch.no_grad():\n",
    "                # здесь градиенты считать не обязательно\n",
    "                <your code here>\n",
    "                acc = ...\n",
    "                loss = ...\n",
    "                \n",
    "                tmp['acc'].append(acc)\n",
    "                tmp['loss'].append(loss)\n",
    "                # <end>\n",
    "                \n",
    "        log.append(dict(\n",
    "            val_loss = np.mean(tmp['loss']),\n",
    "            val_acc = np.mean(tmp['acc']),\n",
    "            train_step=train_step,\n",
    "        ))\n",
    "        \n",
    "        clear_output()\n",
    "        plot_history(log, name='loss')\n",
    "        plot_history(log, name='acc')\n",
    "        plot_grads(grad_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проведите эксперимент с сигмоидой в качестве активационной функции\n",
    "model = DenseNet(20, 10, nn.Sigmoid)\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "x = train_model(model, opt, mnist_train, mnist_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проведите эксперимент с relu в качестве активационной функции\n",
    "model = DenseNet(20, 10, nn.ReLU)\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "x = train_model(model, opt, mnist_train, mnist_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4 (0.2 балла)**. Соберите ResNet с полносвязными слоями и проведите эксперимент с сигмоидой.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseResNet(nn.Module):\n",
    "    def __init__(self, num_layers, hidden_size, activation):\n",
    "        super().__init__()\n",
    "        <your code here>\n",
    "\n",
    "    def forward(self, x):\n",
    "        <your code>\n",
    "\n",
    "model = DenseResNet(10, 16, nn.Sigmoid)\n",
    "# В качестве быстрой проверки корректности попробуем прогнать через сеть тензор нужного размера\n",
    "# [bs, ch, h, w]\n",
    "x = torch.zeros([4, 1, 28, 28])\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseResNet(20, 10, nn.Sigmoid)\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "x = train_model(model, opt, mnist_train, mnist_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 5 (0.1 балла)** \n",
    "Что вы можете сказать про градиенты на разных слоях по этим трем экспериментам?\n",
    "(DenseNet[Sigmoid], DenseNet[ReLU], DenseResNet)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
